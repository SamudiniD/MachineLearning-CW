{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d470e6",
   "metadata": {},
   "source": [
    "# StandardScaler only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2fc7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8836104513064132\n",
      "Precision: 0.8942598187311178\n",
      "Recall: 0.8245125348189415\n",
      "F1 score: 0.8579710144927535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Split into features (X) and labels (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Preprocess the data (standardize the features)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Train the KNN model\n",
    "kValue = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=kValue)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29095d6",
   "metadata": {},
   "source": [
    "# Remove duplications, StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3970025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8836104513064132\n",
      "Precision: 0.8942598187311178\n",
      "Recall: 0.8245125348189415\n",
      "F1 score: 0.8579710144927535\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Split into features (X) and labels (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preprocess the data (standardize the features)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the KNN model\n",
    "kValue = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=kValue)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c273056e",
   "metadata": {},
   "source": [
    "# PCA, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5feb6a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8957654723127035\n",
      "Precision: 0.8972972972972973\n",
      "Recall: 0.8512820512820513\n",
      "F1 score: 0.8736842105263158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Split into features (X) and labels (y)\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Preprocess the data (standardize the features)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 4: Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=50)  # choose the number of principal components to keep\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Step 5: Train the KNN model\n",
    "kValue = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=kValue)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed68f7",
   "metadata": {},
   "source": [
    "# Robust Scaler Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "770af3c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9196234612599565\n",
      "Precision: 0.9172932330827067\n",
      "Recall: 0.8792792792792793\n",
      "F1-score: 0.8978840846366145\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\n",
    "\n",
    "# Scale the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier object with the desired hyperparameters\n",
    "out = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Train the decision tree classifier using the training set\n",
    "out.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the testing set\n",
    "y_pred = out.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using appropriate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd876c44",
   "metadata": {},
   "source": [
    "# Robust Scaler, Remove duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acbc3d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9136975455265242\n",
      "Precision: 0.9232456140350878\n",
      "Recall: 0.8505050505050505\n",
      "F1-score: 0.8853838065194533\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\n",
    "\n",
    "# Scale the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier object with the desired hyperparameters\n",
    "out = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Train the decision tree classifier using the training set\n",
    "out.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the testing set\n",
    "y_pred = out.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using appropriate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea8641",
   "metadata": {},
   "source": [
    "# RobustScaler, Remove Duplications, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bccf237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8740043446777698\n",
      "Precision: 0.8080985915492958\n",
      "Recall: 0.8759541984732825\n",
      "F1-score: 0.8406593406593406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\n",
    "\n",
    "# Scale the features using RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate a PCA object with the desired number of components\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "# Fit the PCA object on the training set\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing set using the fitted PCA object\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier object with the desired hyperparameters\n",
    "out = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Train the decision tree classifier using the training set\n",
    "out.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the testing set\n",
    "y_pred = out.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model using appropriate metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e88da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 is not normally distributed (p=0.000)\n",
      "Feature 1 is not normally distributed (p=0.000)\n",
      "Feature 2 is not normally distributed (p=0.000)\n",
      "Feature 3 is not normally distributed (p=0.000)\n",
      "Feature 4 is not normally distributed (p=0.000)\n",
      "Feature 5 is not normally distributed (p=0.000)\n",
      "Feature 6 is not normally distributed (p=0.000)\n",
      "Feature 7 is not normally distributed (p=0.000)\n",
      "Feature 8 is not normally distributed (p=0.000)\n",
      "Feature 9 is not normally distributed (p=0.000)\n",
      "Feature 10 is not normally distributed (p=0.000)\n",
      "Feature 11 is not normally distributed (p=0.000)\n",
      "Feature 12 is not normally distributed (p=0.000)\n",
      "Feature 13 is not normally distributed (p=0.000)\n",
      "Feature 14 is not normally distributed (p=0.000)\n",
      "Feature 15 is not normally distributed (p=0.000)\n",
      "Feature 16 is not normally distributed (p=0.000)\n",
      "Feature 17 is not normally distributed (p=0.000)\n",
      "Feature 18 is not normally distributed (p=0.000)\n",
      "Feature 19 is not normally distributed (p=0.000)\n",
      "Feature 20 is not normally distributed (p=0.000)\n",
      "Feature 21 is not normally distributed (p=0.000)\n",
      "Feature 22 is not normally distributed (p=0.000)\n",
      "Feature 23 is not normally distributed (p=0.000)\n",
      "Feature 24 is not normally distributed (p=0.000)\n",
      "Feature 25 is not normally distributed (p=0.000)\n",
      "Feature 26 is not normally distributed (p=0.000)\n",
      "Feature 27 is not normally distributed (p=0.000)\n",
      "Feature 28 is not normally distributed (p=0.000)\n",
      "Feature 29 is not normally distributed (p=0.000)\n",
      "Feature 30 is not normally distributed (p=0.000)\n",
      "Feature 31 is not normally distributed (p=0.000)\n",
      "Feature 32 is not normally distributed (p=0.000)\n",
      "Feature 33 is not normally distributed (p=0.000)\n",
      "Feature 34 is not normally distributed (p=0.000)\n",
      "Feature 35 is not normally distributed (p=0.000)\n",
      "Feature 36 is not normally distributed (p=0.000)\n",
      "Feature 37 is not normally distributed (p=0.000)\n",
      "Feature 38 is not normally distributed (p=0.000)\n",
      "Feature 39 is not normally distributed (p=0.000)\n",
      "Feature 40 is not normally distributed (p=0.000)\n",
      "Feature 41 is not normally distributed (p=0.000)\n",
      "Feature 42 is not normally distributed (p=0.000)\n",
      "Feature 43 is not normally distributed (p=0.000)\n",
      "Feature 44 is not normally distributed (p=0.000)\n",
      "Feature 45 is not normally distributed (p=0.000)\n",
      "Feature 46 is not normally distributed (p=0.000)\n",
      "Feature 47 is not normally distributed (p=0.000)\n",
      "Feature 48 is not normally distributed (p=0.000)\n",
      "Feature 49 is not normally distributed (p=0.000)\n",
      "Feature 50 is not normally distributed (p=0.000)\n",
      "Feature 51 is not normally distributed (p=0.000)\n",
      "Feature 52 is not normally distributed (p=0.000)\n",
      "Feature 53 is not normally distributed (p=0.000)\n",
      "Feature 54 is not normally distributed (p=0.000)\n",
      "Feature 55 is not normally distributed (p=0.000)\n",
      "Feature 56 is not normally distributed (p=0.000)\n",
      "Feature 57 is not normally distributed (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "data = pd.read_csv(url, header=None)\n",
    "\n",
    "# Perform the Shapiro-Wilk test on each feature\n",
    "for i in range(data.shape[1]):\n",
    "    stat, p = shapiro(data.iloc[:, i])\n",
    "    if p > 0.05:\n",
    "        print(f\"Feature {i} is normally distributed (p={p:.3f})\")\n",
    "    else:\n",
    "        print(f\"Feature {i} is not normally distributed (p={p:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c3093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
